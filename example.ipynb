{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import json, urllib, hashlib\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wikipedia processing resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'resources/wikipedia/extractedResources/'\n",
    "\n",
    "with open(path+'overall_entity_freq.json', 'r') as f:\n",
    "    overall_entity_freq = json.load(f)\n",
    "\n",
    "with open(path+'entities_overall_dict.json', 'r') as f:\n",
    "    entities_overall_dict = json.load(f)\n",
    "    entities_overall_dict = {x:Counter(y) for x,y in entities_overall_dict.items()}\n",
    "\n",
    "with open(path+'entity_inlink_dict.json', 'r') as f:\n",
    "    entity_inlink_dict = json.load(f)\n",
    "\n",
    "with open(path+'entity_outlink_dict.json', 'r') as f:\n",
    "    entity_outlink_dict = json.load(f)\n",
    "\n",
    "with open(path+'mention_overall_dict.json', 'r') as f:\n",
    "    mention_overall_dict = json.load(f)\n",
    "    mention_overall_dict = {x:Counter(y) for x,y in mention_overall_dict.items()}\n",
    "\n",
    "with open(path+'overall_mentions_freq.json', 'r') as f:\n",
    "    overall_mentions_freq = json.load(f)\n",
    "\n",
    "with open(path+'wikipedia2wikidata.json', 'r') as f:\n",
    "    wikipedia2wikidata = json.load(f)\n",
    "\n",
    "with open(path+'wikidata2wikipedia.json', 'r') as f:\n",
    "    wikidata2wikipedia = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## starting point: a wikidata id or a wikipedia title\n",
    "\n",
    "wikidataId = \"Q90\"\n",
    "if wikidataId in wikidata2wikipedia:\n",
    "    percent_encoded_title = wikidata2wikipedia[wikidataId][0][\"title\"]\n",
    "    # in case of multiple wikipedia pages pointing to the same id you need to pick the one with the highest freq\n",
    "    print (wikidata2wikipedia[wikidataId])\n",
    "else:\n",
    "    print (\"Missing entity in our wikidata2wikipedia Mapping\")\n",
    "\n",
    "\n",
    "# otherwise is you already know the page title you can do the following\n",
    "\n",
    "#wikipedia_title = \"Paris\"\n",
    "#percent_encoded_title = urllib.parse.quote(wikipedia_title)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if \"/\" in percent_encoded_title or len(percent_encoded_title)>200:\n",
    "    percent_encoded_title = hashlib.sha224(percent_encoded_title.encode('utf-8')).hexdigest()\n",
    "\n",
    "with open(path+'Pages/'+percent_encoded_title+\".json\", 'r') as f:\n",
    "    page = json.load(f)\n",
    "\n",
    "inlinks = entity_inlink_dict[percent_encoded_title]\n",
    "outlinks = entity_outlink_dict[percent_encoded_title]\n",
    "freq = overall_entity_freq[percent_encoded_title]\n",
    "name_variations = entities_overall_dict[percent_encoded_title]\n",
    "wikidataId = wikipedia2wikidata[percent_encoded_title]\n",
    "\n",
    "#print (\"inlinks:\",inlinks)\n",
    "#print (\"outlinks:\",outlinks)\n",
    "print (\"freq:\",freq)\n",
    "print (\"name_variations:\",name_variations)\n",
    "print (\"wikidataId\",wikidataId)\n",
    "#print (\"Page Content:\")\n",
    "#print (page)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gazetteer resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wikidata_path = 'resources/wikidata/'\n",
    "\n",
    "df = pd.read_csv(wikidata_path + \"wikidata_gazetteer.csv\", low_memory=False)\n",
    "\n",
    "with open(wikidata_path + 'overall_entity_freq_wikidata.json', 'r') as f:\n",
    "    overall_entity_freq_wikidata = json.load(f)\n",
    "    \n",
    "with open(wikidata_path + 'mentions_to_wikidata_normalized.json', 'r') as f:\n",
    "    mentions_to_wikidata_normalized = json.load(f)\n",
    "    \n",
    "with open(wikidata_path + 'wikidata_to_mentions_normalized.json', 'r') as f:\n",
    "    wikidata_to_mentions_normalized = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df[\"wikidata_id\"] == \"Q203349\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_entity_freq_wikidata[\"Q203349\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wikidata_to_mentions_normalized[\"Q203349\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mentions_to_wikidata_normalized[\"Poole\"]"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c81a5a1980dacfbd83d833a7e56ee30243d7c1ccda80563348485af74244aa8e"
  },
  "kernelspec": {
   "display_name": "Python (py39)",
   "language": "python",
   "name": "py39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
